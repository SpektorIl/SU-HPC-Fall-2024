# Задание
### Перемножение матриц
**Задача:** реализовать алгоритм перемножения матриц  
**Язык:** C++ или Python  
**Выходные данные:** проверка корректности перемножения + время вычисления.  
Реализация должна содержать 2 функции перемножения матриц: на CPU и на GPU с применением CUDA.

# Описание проделанной работы
Данная лабораторная работа была выполнена на языке Python в Jupyter Notebook.

В этой лабораторной работе реализуется умножение матриц с использованием как центрального процессора (CPU), так и графического процессора (GPU)

Таким образом, код демонстрирует, как можно эффективно использовать GPU для ускорения операций умножения матриц по сравнению с традиционным подходом на CPU, и иллюстрирует разницу в производительности между двумя подходами.

**CPU:** функция `matmul_cpu(A, B)` принимает две матрицы `A` и `B` и вычисляет их произведение. Она создает новую матрицу `C` с нулевыми значениями, а затем использует три вложенных цикла `for`, чтобы пройти по всем элементам и вычислить сумму произведений соответствующих элементов.

**GPU:** функция `matmul_gpu_kernel` получает индексы `i` и `j` для доступа к элементам матрицы `C`, а затем вычисляет произведение матриц `A` и `B`, аналогично функции на CPU, но с использованием параллельных потоков. А функция `matmul_gpu(A, B)` копирует матрицы `A` и `B` на GPU, создает пустую матрицу `C` на GPU для хранения результата, определяет количество блоков и потоков, необходимых для выполнения CUDA-ядра, запускает его и затем копирует результат обратно на CPU.

В основном цикле код проходит по различным размерам матриц `N`, генерирует случайные квадратные матрицы для каждого размера, выполняет умножение как на CPU, так и на GPU, и измеряет время выполнения для обеих реализаций. Результаты (время выполнения и соответствие результатов) сохраняются в списках `time_cpu` и `time_gpu`.

Таким образом, код демонстрирует, как можно эффективно использовать GPU для ускорения операций умножения матриц по сравнению с традиционным подходом на CPU, и иллюстрирует разницу в производительности между двумя подходами.

# Анализ результатов эксперимента
После выполнения умножения для всех размеров матриц, код выводит в консоль информацию о размере матрицы, времени выполнения на CPU и GPU, а также проверяет, совпадают ли результаты:
| Размер матрицы | Время CPU (с) | Время GPU (с) | Соответствие   |
|----------------|---------------|---------------|----------------|
| 100            | 0.419082      | 0.276477      | True           |
| 200            | 3.890673      | 0.008193      | True           |
| 300            | 12.690911     | 0.019606      | True           |
| 500            | 58.088804     | 0.076809      | True           |
| 700            | 158.090950    | 0.198220      | True           |
| 900            | 236.772254    | 0.190238      | True           |
| 1000           | 476.314713    | 0.252833      | True           |
| 2000           | 4761.074888   | 0.653611      | True           |

Создаются графики, отображающие время выполнения для CPU и GPU в зависимости от размера матриц, а также график, показывающий ускорение вычислений на GPU по сравнению с CPU (отношение времени CPU к времени GPU).  

![alt text](/assets/MATMUL-1.png)
![alt text](/assets/MATMUL-2.png)
